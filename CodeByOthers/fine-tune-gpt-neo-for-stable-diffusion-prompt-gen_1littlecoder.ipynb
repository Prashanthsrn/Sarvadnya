{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n!nvidia-smi","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-03T14:53:28.876471Z","iopub.execute_input":"2022-10-03T14:53:28.876887Z","iopub.status.idle":"2022-10-03T14:53:30.230086Z","shell.execute_reply.started":"2022-10-03T14:53:28.876770Z","shell.execute_reply":"2022-10-03T14:53:30.228131Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Mon Oct  3 14:53:30 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   47C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget -O prompts.csv https://raw.githubusercontent.com/krea-ai/open-prompts/main/data/1k.csv","metadata":{"execution":{"iopub.status.busy":"2022-10-03T14:53:56.048158Z","iopub.execute_input":"2022-10-03T14:53:56.050989Z","iopub.status.idle":"2022-10-03T14:53:57.441739Z","shell.execute_reply.started":"2022-10-03T14:53:56.050953Z","shell.execute_reply":"2022-10-03T14:53:57.439981Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2022-10-03 14:53:57--  https://raw.githubusercontent.com/krea-ai/open-prompts/main/data/1k.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1027887 (1004K) [text/plain]\nSaving to: ‘prompts.csv’\n\nprompts.csv         100%[===================>]   1004K  --.-KB/s    in 0.02s   \n\n2022-10-03 14:53:57 (44.6 MB/s) - ‘prompts.csv’ saved [1027887/1027887]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-10-03T14:54:01.828516Z","iopub.execute_input":"2022-10-03T14:54:01.829027Z","iopub.status.idle":"2022-10-03T14:54:03.055341Z","shell.execute_reply.started":"2022-10-03T14:54:01.828981Z","shell.execute_reply":"2022-10-03T14:54:03.053672Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb  prompts  prompts.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"prompts = pd.read_csv(\"prompts.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-10-03T14:54:16.534957Z","iopub.execute_input":"2022-10-03T14:54:16.535580Z","iopub.status.idle":"2022-10-03T14:54:16.609028Z","shell.execute_reply.started":"2022-10-03T14:54:16.535534Z","shell.execute_reply":"2022-10-03T14:54:16.607092Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"prompts","metadata":{"execution":{"iopub.status.busy":"2022-10-03T14:55:16.215335Z","iopub.execute_input":"2022-10-03T14:55:16.215746Z","iopub.status.idle":"2022-10-03T14:55:16.233656Z","shell.execute_reply.started":"2022-10-03T14:55:16.215716Z","shell.execute_reply":"2022-10-03T14:55:16.231981Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                prompt  \\\n0    A portrait photo of a kangaroo wearing an oran...   \n1             inmates with cow heads inside a jailcell   \n2    daguerrotype of a corgi astronaut on the moon,...   \n3    totem animal tribal chaman vodoo mask feather ...   \n4                                          p. cubensis   \n..                                                 ...   \n993                        warrior tattoo, magnificent   \n994  nematode worms find a plant cell, microscopy, ...   \n995  hyperrealism close-up portrait of beautiful me...   \n996  an extremely detailed masterpiece of a mouse w...   \n997  a cinematic headshot portrait of a young woman...   \n\n                                              raw_data  \n0    {\"image_uri\": \"PENDING\", \"modifiers\": [\"portra...  \n1    {\"image_uri\": \"PENDING\", \"modifiers\": [\"inmate...  \n2    {\"image_uri\": \"PENDING\", \"modifiers\": [\"daguer...  \n3    {\"image_uri\": \"PENDING\", \"modifiers\": [\"totem ...  \n4    {\"image_uri\": \"PENDING\", \"modifiers\": [\"p cube...  \n..                                                 ...  \n993  {\"image_uri\": \"PENDING\", \"modifiers\": [\"warrio...  \n994  {\"image_uri\": \"PENDING\", \"modifiers\": [\"nemato...  \n995  {\"image_uri\": \"PENDING\", \"modifiers\": [\"hyperr...  \n996  {\"image_uri\": \"PENDING\", \"modifiers\": [\"extrem...  \n997  {\"image_uri\": \"PENDING\", \"modifiers\": [\"cinema...  \n\n[998 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>raw_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A portrait photo of a kangaroo wearing an oran...</td>\n      <td>{\"image_uri\": \"PENDING\", \"modifiers\": [\"portra...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>inmates with cow heads inside a jailcell</td>\n      <td>{\"image_uri\": \"PENDING\", \"modifiers\": [\"inmate...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>daguerrotype of a corgi astronaut on the moon,...</td>\n      <td>{\"image_uri\": \"PENDING\", \"modifiers\": [\"daguer...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>totem animal tribal chaman vodoo mask feather ...</td>\n      <td>{\"image_uri\": \"PENDING\", \"modifiers\": [\"totem ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>p. cubensis</td>\n      <td>{\"image_uri\": \"PENDING\", \"modifiers\": [\"p cube...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>993</th>\n      <td>warrior tattoo, magnificent</td>\n      <td>{\"image_uri\": \"PENDING\", \"modifiers\": [\"warrio...</td>\n    </tr>\n    <tr>\n      <th>994</th>\n      <td>nematode worms find a plant cell, microscopy, ...</td>\n      <td>{\"image_uri\": \"PENDING\", \"modifiers\": [\"nemato...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>hyperrealism close-up portrait of beautiful me...</td>\n      <td>{\"image_uri\": \"PENDING\", \"modifiers\": [\"hyperr...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>an extremely detailed masterpiece of a mouse w...</td>\n      <td>{\"image_uri\": \"PENDING\", \"modifiers\": [\"extrem...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>a cinematic headshot portrait of a young woman...</td>\n      <td>{\"image_uri\": \"PENDING\", \"modifiers\": [\"cinema...</td>\n    </tr>\n  </tbody>\n</table>\n<p>998 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"prompts_gt6 = prompts.loc[prompts.prompt.str.split(' ').str.len() > 6]","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:00:24.533904Z","iopub.execute_input":"2022-10-03T15:00:24.534473Z","iopub.status.idle":"2022-10-03T15:00:24.547612Z","shell.execute_reply.started":"2022-10-03T15:00:24.534434Z","shell.execute_reply":"2022-10-03T15:00:24.546217Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"! pip install aitextgen -q","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:01:56.299834Z","iopub.execute_input":"2022-10-03T15:01:56.300286Z","iopub.status.idle":"2022-10-03T15:02:16.625861Z","shell.execute_reply.started":"2022-10-03T15:01:56.300255Z","shell.execute_reply":"2022-10-03T15:02:16.624213Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"model=\"EleutherAI/gpt-neo-125M\"","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:08:53.157528Z","iopub.execute_input":"2022-10-03T15:08:53.157959Z","iopub.status.idle":"2022-10-03T15:08:53.164512Z","shell.execute_reply.started":"2022-10-03T15:08:53.157901Z","shell.execute_reply":"2022-10-03T15:08:53.162988Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"prompts_gt6 = prompts_gt6.drop('raw_data', axis = 1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:07:19.973209Z","iopub.execute_input":"2022-10-03T15:07:19.973622Z","iopub.status.idle":"2022-10-03T15:07:19.981938Z","shell.execute_reply.started":"2022-10-03T15:07:19.973577Z","shell.execute_reply":"2022-10-03T15:07:19.980071Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"prompts_gt6.to_csv(\"input_text_cleaned.txt\", columns=[\"prompt\"], header=False, index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:07:41.442957Z","iopub.execute_input":"2022-10-03T15:07:41.443384Z","iopub.status.idle":"2022-10-03T15:07:41.460225Z","shell.execute_reply.started":"2022-10-03T15:07:41.443354Z","shell.execute_reply":"2022-10-03T15:07:41.458768Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from aitextgen.TokenDataset import TokenDataset","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:07:56.915210Z","iopub.execute_input":"2022-10-03T15:07:56.915746Z","iopub.status.idle":"2022-10-03T15:08:08.316368Z","shell.execute_reply.started":"2022-10-03T15:07:56.915702Z","shell.execute_reply":"2022-10-03T15:08:08.314901Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"data = TokenDataset('./input_text_cleaned.txt', line_by_line=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:08:10.463010Z","iopub.execute_input":"2022-10-03T15:08:10.465655Z","iopub.status.idle":"2022-10-03T15:08:10.882178Z","shell.execute_reply.started":"2022-10-03T15:08:10.465610Z","shell.execute_reply":"2022-10-03T15:08:10.880864Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/896 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de522687a8ac46549644075b1e167bbb"}},"metadata":{}}]},{"cell_type":"code","source":"from aitextgen import aitextgen\n","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:08:38.515773Z","iopub.execute_input":"2022-10-03T15:08:38.517099Z","iopub.status.idle":"2022-10-03T15:08:38.524060Z","shell.execute_reply.started":"2022-10-03T15:08:38.517033Z","shell.execute_reply":"2022-10-03T15:08:38.522656Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# ai = aitextgen(tf_gpt2=\"124M\",  to_gpu=True)\nai = aitextgen(model = model,  to_gpu=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:26:53.063403Z","iopub.execute_input":"2022-10-03T15:26:53.063850Z","iopub.status.idle":"2022-10-03T15:27:28.235130Z","shell.execute_reply.started":"2022-10-03T15:26:53.063818Z","shell.execute_reply":"2022-10-03T15:27:28.233456Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /kaggle/working/aitextgen/tmpu8sup6me\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da925c525d0440689a1d0569a4e53350"}},"metadata":{}},{"name":"stderr","text":"storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/pytorch_model.bin in cache at aitextgen/b0ace3b93ace62067a246888f1e54e2d3ec20807d4d3e27ac602eef3b7091c0b.6525df88f1d5a2d33d95ce2458ef6af9658fe7d1393d6707e0e318779ccc68ff\ncreating metadata file for aitextgen/b0ace3b93ace62067a246888f1e54e2d3ec20807d4d3e27ac602eef3b7091c0b.6525df88f1d5a2d33d95ce2458ef6af9658fe7d1393d6707e0e318779ccc68ff\nhttps://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /kaggle/working/aitextgen/tmp3us8kvj1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/560 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a209eb9e0f564ea98bc3e0e6bc4dc52b"}},"metadata":{}},{"name":"stderr","text":"storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer_config.json in cache at aitextgen/3cc88b3aa29bb2546db2dc21783292e2a086bb7158c7b5ceddeb24158a85c183.e74f7c3643ee79eb023ead36008be72fe726dada60fa3b2a0569925cfefa1e74\ncreating metadata file for aitextgen/3cc88b3aa29bb2546db2dc21783292e2a086bb7158c7b5ceddeb24158a85c183.e74f7c3643ee79eb023ead36008be72fe726dada60fa3b2a0569925cfefa1e74\nhttps://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /kaggle/working/aitextgen/tmpx87qu3ct\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68738eb9926b40ccb892116b96169e74"}},"metadata":{}},{"name":"stderr","text":"storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/vocab.json in cache at aitextgen/08c00c4159e921d4c941ac75732643373aba509d9b352a82bbbb043a94058d98.a552555fdda56a1c7c9a285bccfd44ac8e4b9e26c8c9b307831b3ea3ac782b45\ncreating metadata file for aitextgen/08c00c4159e921d4c941ac75732643373aba509d9b352a82bbbb043a94058d98.a552555fdda56a1c7c9a285bccfd44ac8e4b9e26c8c9b307831b3ea3ac782b45\nhttps://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /kaggle/working/aitextgen/tmpfmcb1mr5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5a00e0489cb4db8832f2bd0c472f2f5"}},"metadata":{}},{"name":"stderr","text":"storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/merges.txt in cache at aitextgen/12305762709d884a770efe7b0c68a7f4bc918da44e956058d43da0d12f7bea20.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\ncreating metadata file for aitextgen/12305762709d884a770efe7b0c68a7f4bc918da44e956058d43da0d12f7bea20.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\nhttps://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /kaggle/working/aitextgen/tmpjtstvklz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"490a66b6b57043ab9ce3bf4402f7301e"}},"metadata":{}},{"name":"stderr","text":"storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/special_tokens_map.json in cache at aitextgen/6c3239a63aaf46ec7625b38abfe41fc2ce0b25f90800aefe6526256340d4ab6d.2b8bf81243d08385c806171bc7ced6d2a0dcc7f896ca637f4e777418f7f0cc3c\ncreating metadata file for aitextgen/6c3239a63aaf46ec7625b38abfe41fc2ce0b25f90800aefe6526256340d4ab6d.2b8bf81243d08385c806171bc7ced6d2a0dcc7f896ca637f4e777418f7f0cc3c\nloading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/vocab.json from cache at aitextgen/08c00c4159e921d4c941ac75732643373aba509d9b352a82bbbb043a94058d98.a552555fdda56a1c7c9a285bccfd44ac8e4b9e26c8c9b307831b3ea3ac782b45\nloading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/merges.txt from cache at aitextgen/12305762709d884a770efe7b0c68a7f4bc918da44e956058d43da0d12f7bea20.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\nloading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer.json from cache at None\nloading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/special_tokens_map.json from cache at aitextgen/6c3239a63aaf46ec7625b38abfe41fc2ce0b25f90800aefe6526256340d4ab6d.2b8bf81243d08385c806171bc7ced6d2a0dcc7f896ca637f4e777418f7f0cc3c\nloading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer_config.json from cache at aitextgen/3cc88b3aa29bb2546db2dc21783292e2a086bb7158c7b5ceddeb24158a85c183.e74f7c3643ee79eb023ead36008be72fe726dada60fa3b2a0569925cfefa1e74\nhttps://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpx90fh_6f\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/0.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d96160be6cd947fd8d48c7395ea406b9"}},"metadata":{}},{"name":"stderr","text":"storing https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\ncreating metadata file for /root/.cache/huggingface/transformers/29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n","output_type":"stream"}]},{"cell_type":"code","source":"ai.train('input_text_cleaned.txt',\n         line_by_line=True,\n         from_cache=False,\n         num_steps=500,\n         generate_every=100,\n         save_every=500,\n         save_gdrive=False,\n         learning_rate=1e-3,\n         fp16=False,\n         batch_size=1, \n         )","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:31:13.850496Z","iopub.execute_input":"2022-10-03T15:31:13.851012Z","iopub.status.idle":"2022-10-03T15:35:26.842446Z","shell.execute_reply.started":"2022-10-03T15:31:13.850974Z","shell.execute_reply":"2022-10-03T15:35:26.838204Z"},"trusted":true},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/896 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccbd707ec023464494e38aae1b25333d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:448: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/configuration_validator.py:259: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n  f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1f145d2d5849c083c302455418c9a6"}},"metadata":{}},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[1m100 steps reached: generating sample texts.\u001b[0m\n==========\n  cinematic still from movie still than his face, in his heart, outrun, vaporware, digital painting, artstation, concept art, smooth, sharp focus, illustration, art alphonse mucha, lois van baarle, ilya kuvshinov, rossdraws, octane render, unreal 5, volumetric, 8 k, unreal 5 mm lens, unreal lens flare, 8 k, cinematic filmes, trending on artstation, unreal 5\"\n\n==========\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[1m200 steps reached: generating sample texts.\u001b[0m\n==========\n and jean claude meziere and moebius and will eugene de blaas.\n\n==========\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[1m300 steps reached: generating sample texts.\u001b[0m\n==========\n a portrait of a cybernetic mistress of the dark, cyberpunk concept art by pete mohrbacher and wlop and artgerm and josan gonzales, digital, highly detailed, intricate, sci-fi, synthwave, synthwave, synthwave, synthwave, synthwave, synthwave, synthwave, synthwave, synthwave, 8k, highly detailed, intricate, sci-fi, synthwave, 8k, highly detailed, trending on artstation, deviantart, by pete mohrbacher and gustav mckernan and william - adolphe bouguereau\"\n\n==========\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[1m400 steps reached: generating sample texts.\u001b[0m\n==========\na, character concept, portrait, matte, sharp focus, hd, character design, by Greg Rutkowski, talking to alphonse mucha, artgerm, concept art, 4 k, hyperrealism, hyperdetailed\"\n\n==========\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[1m500 steps reached: saving model to /trained_model\u001b[0m\n\u001b[1m500 steps reached: generating sample texts.\u001b[0m\n==========\n of a woman with long dark hair and red eyes, wearing a red dress, holding a bouquet of flowing flowers, drenched body, wet dripping hair, emerging from the water, fantasy, regal, fractal crystal, fractal gems, by stanley artgerm lau, greg rutkowski, alphonse mucha, loish, norman rockwell\"\n\n==========\n","output_type":"stream"}]},{"cell_type":"code","source":"ai.save()\n","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:35:35.568711Z","iopub.execute_input":"2022-10-03T15:35:35.569173Z","iopub.status.idle":"2022-10-03T15:35:37.879800Z","shell.execute_reply.started":"2022-10-03T15:35:35.569135Z","shell.execute_reply":"2022-10-03T15:35:37.877931Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"prompt_ai = aitextgen(model_folder = '.', to_gpu=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:35:44.080133Z","iopub.execute_input":"2022-10-03T15:35:44.080685Z","iopub.status.idle":"2022-10-03T15:35:47.958696Z","shell.execute_reply.started":"2022-10-03T15:35:44.080633Z","shell.execute_reply":"2022-10-03T15:35:47.957302Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"print(prompt_ai.generate(prompt = \"astronaut \"))","metadata":{"execution":{"iopub.status.busy":"2022-10-03T16:00:38.493669Z","iopub.execute_input":"2022-10-03T16:00:38.494155Z","iopub.status.idle":"2022-10-03T16:00:41.154110Z","shell.execute_reply.started":"2022-10-03T16:00:38.494123Z","shell.execute_reply":"2022-10-03T16:00:41.152537Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"\u001b[1mastronaut \u001b[0mernst haeckel, donato giancola, boris vallejo, drew struzan realistic detailed oil painting, urban horror, frank frazetta, saturated colors. realistic shaded lighting, sharp, depth of field, trending on art station, a night, lit by stars, detailed and intricate environment, Tiled wall, by Matteo Pasqualin Volegov, Greg Rutkowski, Greg Rutkowski, Pete Morbacher, Tuomas Korpi, tekkon kinreet, volumetric, octane render, ray tracing, donato giancola, tekkon kinreet, volumetric, octane render, dramatic lighting,. Peter mohrbacher. Mayan by Takato Yamamoto. David Hockney.\"\n\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"print(prompt_ai.generate_one(prompt = \"astronaut \"))","metadata":{"execution":{"iopub.status.busy":"2022-10-03T16:00:47.788427Z","iopub.execute_input":"2022-10-03T16:00:47.789865Z","iopub.status.idle":"2022-10-03T16:00:49.162567Z","shell.execute_reply.started":"2022-10-03T16:00:47.789804Z","shell.execute_reply":"2022-10-03T16:00:49.160959Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"astronaut ernst haeckel, bernich, walter everett, lost edges, by yoichi hatakenaka, masashi kojima, josan gonzales and dan mumford, ayami kojima, takato yamamoto, barclay shaw 8 k, sharp focus, vibrant, intricate, octane render, ray tracing, hphstone, art by Takato Yamamoto and Simon Stalenhag\"\n\n","output_type":"stream"}]},{"cell_type":"code","source":"ai.save_for_upload('sd-prompt-generator-gpt-neo')","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:37:02.386457Z","iopub.execute_input":"2022-10-03T15:37:02.386919Z","iopub.status.idle":"2022-10-03T15:37:03.866577Z","shell.execute_reply.started":"2022-10-03T15:37:02.386868Z","shell.execute_reply":"2022-10-03T15:37:03.865197Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stderr","text":"tokenizer config file saved in sd-prompt-generator-gpt-neo/tokenizer_config.json\nSpecial tokens file saved in sd-prompt-generator-gpt-neo/special_tokens_map.json\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:47:40.027298Z","iopub.execute_input":"2022-10-03T15:47:40.027734Z","iopub.status.idle":"2022-10-03T15:47:40.082735Z","shell.execute_reply.started":"2022-10-03T15:47:40.027698Z","shell.execute_reply":"2022-10-03T15:47:40.081369Z"},"trusted":true},"execution_count":65,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"384123fcc46e4e6ba6ea8464f5283e05"}},"metadata":{}}]},{"cell_type":"code","source":"!sudo apt-get install git-lfs","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:52:33.454148Z","iopub.execute_input":"2022-10-03T15:52:33.454617Z","iopub.status.idle":"2022-10-03T15:52:41.563701Z","shell.execute_reply.started":"2022-10-03T15:52:33.454580Z","shell.execute_reply":"2022-10-03T15:52:41.562018Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following NEW packages will be installed:\n  git-lfs\n0 upgraded, 1 newly installed, 0 to remove and 65 not upgraded.\nNeed to get 3316 kB of archives.\nAfter this operation, 11.1 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 git-lfs amd64 2.9.2-1 [3316 kB]\nFetched 3316 kB in 0s (14.5 MB/s)\nSelecting previously unselected package git-lfs.\n(Reading database ... 108827 files and directories currently installed.)\nPreparing to unpack .../git-lfs_2.9.2-1_amd64.deb ...\nUnpacking git-lfs (2.9.2-1) ...\nSetting up git-lfs (2.9.2-1) ...\nProcessing triggers for man-db (2.9.1-1) ...\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install --upgrade huggingface_hub -q","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:53:42.809758Z","iopub.execute_input":"2022-10-03T15:53:42.810264Z","iopub.status.idle":"2022-10-03T15:53:58.049434Z","shell.execute_reply.started":"2022-10-03T15:53:42.810230Z","shell.execute_reply":"2022-10-03T15:53:58.047738Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncached-path 1.1.5 requires huggingface-hub<0.9.0,>=0.8.1, but you have huggingface-hub 0.10.0 which is incompatible.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Uploading the model to Hugging Face Model Hub","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import HfApi","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:56:34.472190Z","iopub.execute_input":"2022-10-03T15:56:34.472635Z","iopub.status.idle":"2022-10-03T15:56:34.478842Z","shell.execute_reply.started":"2022-10-03T15:56:34.472604Z","shell.execute_reply":"2022-10-03T15:56:34.477342Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"api = HfApi()","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:56:44.681183Z","iopub.execute_input":"2022-10-03T15:56:44.681678Z","iopub.status.idle":"2022-10-03T15:56:44.688019Z","shell.execute_reply.started":"2022-10-03T15:56:44.681630Z","shell.execute_reply":"2022-10-03T15:56:44.686324Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"\napi.upload_folder(\n    folder_path=\"./sd-prompt-generator-gpt-neo\",\n    path_in_repo = \".\",\n    repo_id=\"Amrrs/sd-prompt-generator-gpt-neo\",\n    repo_type=\"model\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-10-03T15:58:35.427139Z","iopub.execute_input":"2022-10-03T15:58:35.427673Z","iopub.status.idle":"2022-10-03T15:58:59.693671Z","shell.execute_reply.started":"2022-10-03T15:58:35.427632Z","shell.execute_reply":"2022-10-03T15:58:59.692126Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/Amrrs/sd-prompt-generator-gpt-neo/tree/main/.'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}